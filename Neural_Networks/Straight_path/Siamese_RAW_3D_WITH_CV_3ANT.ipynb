{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Νευρωνικά Δίκτυα"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Παρακάτω θα παρουσιάσουμε μερικές αρχιτεκτονικές νευρωνικών δικτύων."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Συναρτήσεις "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Οι παρακάτω βοηθητικές συναρτήσεις θα χρησιμοποιηθούν για να κάνουμε train και test το μοντέλο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Αρχικά κάνουμε τα απαραίτητα imports και ορίζουμε την συσκευή που θα χρησιμοποιήσουμε (cpu/gpu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device, imports complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import nn\n",
        "import os\n",
        "from torch.optim import lr_scheduler\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "# For implementation of ReLock\n",
        "labels_holdout = []\n",
        "info_holdout = []\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device, imports complete!'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Στην συνέχεια ορίζουμε την πρώτη συνάρτηση η οποία δέχεται ένα μοντέλο, το training dataset, την συνάρτηση λάθους, τον optimizer, και την συσκευή που χρησιμοποιούμε. Προχωράει το training κατά ένα βήμα και επιστρέφει την απώλεια."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device = 'cpu'):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0\n",
        "    for X_batch, y_batch in data_loader:\n",
        "        # Send data to GPU\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        size = int(X_batch.shape[1]/ 3)\n",
        "        antenna1 = X_batch[:,:size]\n",
        "        antenna2 = X_batch[:,size: 2* size]\n",
        "        antenna3 = X_batch[:,2*size:]\n",
        "        y_pred = model(antenna1, antenna2, antenna3)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "        # Zero gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the weights\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping to prevent gradients exploding\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    return train_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ομοίως η παρακάτω συνάρτηση κάνει test το μοντέλο σε κάθε εποχή, και επιστρέφει την απώλεια."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device = 'cpu'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    with torch.inference_mode():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            # Send data to GPU\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            size = int(X_batch.shape[1]/ 3)\n",
        "            antenna1 = X_batch[:,:size]\n",
        "            antenna2 = X_batch[:,size: 2* size]\n",
        "            antenna3 = X_batch[:,2*size:]\n",
        "\n",
        "            y_test_pred = model(antenna1, antenna2, antenna3)\n",
        "            test_loss += loss_fn(y_test_pred, y_batch).item()\n",
        "    \n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ορίζουμε μία κλάση έτσι ώστε το μοντέλο μας να σταματάει νωρίς όταν παρατηρεί ότι το test loss αυξάνεται η μέθοδος αυτή είναι γνωστή και ως early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0.0, verbose=False, path='best_model.pth'):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.verbose = verbose\n",
        "        self.path = path\n",
        "\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            torch.save(model.state_dict(), self.path)\n",
        "            if self.verbose:\n",
        "                print(f\"Validation loss decreased to {val_loss:.6f}. Saving model...\")\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"No improvement. Counter: {self.counter}/{self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "    \n",
        "    def get_best_loss(self):\n",
        "        return self.best_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Η βασική συνάρτηση, επαναληπτικά για όσες εποχές έχουμε διαλέξει κάνει train και test το μοντέλο, και ανά 10 εποχές εκτυπώνει τα αποτελέσματα. Επιστρέφει 2 πίνακες με τις συνολικές απώλειες σε κάθε επανάληψη."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_model(epoch: int, \n",
        "                     model: torch.nn.Module,\n",
        "                     train_loader: torch.utils.data.DataLoader,\n",
        "                     test_loader: torch.utils.data.DataLoader,\n",
        "                     loss_fn: torch.nn.Module,\n",
        "                     optimizer: torch.optim.Optimizer,\n",
        "                     scheduler,\n",
        "                     early_stopper = None,\n",
        "                     device: torch.device = 'cpu',\n",
        "                     test: bool = True,\n",
        "                     verbose: bool = True):\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    train_loss_arr = []\n",
        "    test_loss_arr = []\n",
        "    \n",
        "    if(test):\n",
        "        for epochs in range(epoch):\n",
        "            # Train for one epoch\n",
        "            epoch_loss = train_step(model, train_loader, loss_fn, optimizer, device)\n",
        "            train_loss_arr.append(epoch_loss / len(train_loader))\n",
        "\n",
        "            # Scheduler update\n",
        "            scheduler.step(epoch_loss)\n",
        "            after_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Evaluate on test set\n",
        "            test_loss = test_step(model, test_loader, loss_fn, device)\n",
        "            test_loss_arr.append(test_loss / len(test_loader))\n",
        "\n",
        "            # Print progress\n",
        "            if verbose == True:\n",
        "                if (epochs % 10 == 0) or (epochs == 0):\n",
        "                    print(f'Epoch {epochs} | Loss train: {train_loss_arr[-1]:.6f} | Loss test: {test_loss_arr[-1]:.6f} | lr = {after_lr}')\n",
        "                elif epochs + 1 == epoch:\n",
        "                    print(f'Epoch {epoch} | Loss train: {train_loss_arr[-1]:.6f} | Loss test: {test_loss_arr[-1]:.6f} | lr = {after_lr}')\n",
        "\n",
        "            # Early stopping check\n",
        "            early_stopper(test_loss_arr[-1], model)\n",
        "            if early_stopper.early_stop:\n",
        "                if verbose == True:\n",
        "                    print(f\"Early stopping at epoch {epochs}\")\n",
        "                break\n",
        "\n",
        "        # Load the best model weights after stopping\n",
        "        if early_stopper.path is not None:\n",
        "            model.load_state_dict(torch.load(early_stopper.path, weights_only= True))\n",
        "            if verbose == True:\n",
        "                print(f\"Loaded best model from {early_stopper.path}\")\n",
        "\n",
        "        return train_loss_arr, test_loss_arr, early_stopper.get_best_loss(), epochs\n",
        "    else:\n",
        "        for epochs in range(epoch):\n",
        "            # Train for one epoch\n",
        "            epoch_loss = train_step(model, train_loader, loss_fn, optimizer, device)\n",
        "            train_loss_arr.append(epoch_loss / len(train_loader))\n",
        "\n",
        "            # Scheduler update\n",
        "            scheduler.step(epoch_loss)\n",
        "            after_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Print progress\n",
        "            if verbose == True:\n",
        "                if (epochs % 10 == 0) or (epochs == 0):\n",
        "                    print(f'Epoch {epochs} | Loss train: {train_loss_arr[-1]:.6f} | lr = {after_lr}')\n",
        "                elif epochs + 1 == epoch:\n",
        "                    print(f'Epoch {epoch} | Loss train: {train_loss_arr[-1]:.6f} | lr = {after_lr}')\n",
        "        return train_loss_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Η συνάρτηση είναι παρόμοια με την test_step με την διαφορά ότι επιστρέφει ένα dictionary με τα βασικά στοιχεία του μοντέλου."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_model_3d(model: torch.nn.Module, \n",
        "                  data_loader: torch.utils.data.DataLoader, \n",
        "                  scaler,\n",
        "                  device: torch.device = 'cpu',\n",
        "                  verbose=True):\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            size = int(X.shape[1]/ 3)\n",
        "            antenna1 = X[:,:size]\n",
        "            antenna2 = X[:,size:2 *size]\n",
        "            antenna3 = X[:, 2*size :]\n",
        "            y_pred = model(antenna1, antenna2, antenna3)\n",
        "\n",
        "            # Move to CPU and collect all predictions and targets\n",
        "            all_preds.append(y_pred.cpu())\n",
        "            all_targets.append(y.cpu())\n",
        "\n",
        "    # Concatenate all batches\n",
        "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
        "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
        "\n",
        "    # Reverse scaling\n",
        "    y_pred_real = scaler.inverse_transform(all_preds)\n",
        "    y_true_real = scaler.inverse_transform(all_targets)\n",
        "\n",
        "    # Calculate average Euclidean distance (in cm)\n",
        "    distances = np.linalg.norm(y_pred_real - y_true_real, axis=1)\n",
        "    mean_distance_error = np.mean(distances)\n",
        "    std_distance_error = np.std(distances)\n",
        "\n",
        "    # Plot real data VS predicted in 3D\n",
        "    if verbose:\n",
        "        fig = plt.figure(figsize=(15, 15))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "        number_of_points = 20\n",
        "\n",
        "        # Plot ground truth points\n",
        "        ax.scatter(\n",
        "            y_true_real[:number_of_points, 0], \n",
        "            y_true_real[:number_of_points, 1], \n",
        "            y_true_real[:number_of_points, 2], \n",
        "            color='blue', label='Ground Truth', s=100\n",
        "        )\n",
        "\n",
        "        # Plot predicted points\n",
        "        ax.scatter(\n",
        "            y_pred_real[:number_of_points, 0], \n",
        "            y_pred_real[:number_of_points, 1], \n",
        "            y_pred_real[:number_of_points, 2], \n",
        "            color='red', label='Predicted', s=100\n",
        "        )\n",
        "\n",
        "        # Draw lines connecting corresponding points\n",
        "        for i, (gt, pred) in enumerate(zip(y_true_real[:number_of_points], y_pred_real[:number_of_points])):\n",
        "            ax.plot(\n",
        "                [gt[0], pred[0]], \n",
        "                [gt[1], pred[1]], \n",
        "                [gt[2], pred[2]], \n",
        "                color='gray', linestyle='--', linewidth=1\n",
        "            )\n",
        "            \n",
        "            # Calculate the midpoint of the line for placing the text\n",
        "            mid_x = (gt[0] + pred[0]) / 2\n",
        "            mid_y = (gt[1] + pred[1]) / 2\n",
        "            mid_z = (gt[2] + pred[2]) / 2\n",
        "            \n",
        "            # Annotate the line with the corresponding distance from the distances array\n",
        "            ax.text(mid_x, mid_y, mid_z, f'{distances[i]:.2f} cm', fontsize=9, ha='center', va='bottom', color='black',\n",
        "                    bbox=dict(facecolor='white', edgecolor='none', alpha=0.3))\n",
        "\n",
        "        # Add labels and legend\n",
        "        ax.set_xlabel('X')\n",
        "        ax.set_ylabel('Y')\n",
        "        ax.set_zlabel('Z')\n",
        "        ax.set_title(f'Ground Truth vs Predicted Points\\nMean Distance Error: {mean_distance_error:.2f} cm, Std: {std_distance_error:.2f} cm')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "    return {\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"mean_distance_error_cm\": mean_distance_error.item(),\n",
        "        \"std\": std_distance_error.item()\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Η συνάρτηση αυτή χρησιμοποιείται για να εμφανίσει τις κανονικοποιημένες στο (0,1) train_loss και test_loss curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_results(train_arr, test_arr):\n",
        "    # Plot the loss curves\n",
        "    train_arr = (train_arr - np.min(train_arr)) / (np.max(train_arr) - np.min(train_arr))\n",
        "    test_arr = (test_arr - np.min(test_arr)) / (np.max(test_arr) - np.min(test_arr))\n",
        "    \n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(train_arr, label='Train Loss')\n",
        "    plt.plot(test_arr, label='Test Loss')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Normalized Loss\")\n",
        "    plt.title(\"Normalized Training Loss\")\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Εισαγωγή δεδομένων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Κάνουμε scale και το Y οπότε σε περίπτωση τυχαίου διανύσματος θα πρέπει να το κάνουμε και αυτό scale, και μετά το output να το επαναφέρουμε."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Έχοντας δοκιμάσει να κανονικοποιήσουμε τα δεδομένα εισόδου σε [-1,1] και τα δεδομένα εξόδου με την χρήση του standardscaler, τα αποτελέσματα είναι **ελαφρώς χειρότερα** από το να κανονικοποιήσουμε και την είσοδο και την έξοδο με τον standard scaler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Κάνοντας χρήση της μεθόδου [-1,1] τοσο για την είσοδο όσο για την έξοδο τα αποτελέσματα είναι **σαφώς χειρότερα**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Για την ώρα κρατάμε το [-1,1] για την είσοδο και το StandardScaler για την έξοδο."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ανάλογα με τον ποιον φάκελο θέλουμε να διαβάσουμε αλλάζουμε το νουμεράκι."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4074, 500, 12), (4074, 3), (30, 500, 12), (30, 3))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the directory of the script\n",
        "parent_dir = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
        "\n",
        "parent_dir = os.path.join(parent_dir, '..', '..', 'Experiments', 'Raw_Data_Triple_Antenna_1') \n",
        "\n",
        "\n",
        "rfid_label = np.load(f\"{parent_dir}\\\\labels.npy\")\n",
        "info_tensor = np.load(f\"{parent_dir}\\\\dataset.npy\")\n",
        "\n",
        "holdout_tensor = np.load(f\"{parent_dir}\\\\holdout_dataset.npy\")\n",
        "holdout_labels = np.load(f\"{parent_dir}\\\\holdout_labels.npy\")\n",
        "\n",
        "info_tensor.shape , rfid_label.shape, holdout_tensor.shape, holdout_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[107.3 107.3 107.3 ... 107.3 107.3 107.3]\n",
            " [107.3 107.3 107.3 ... 107.3 107.3 107.3]\n",
            " [152.8 152.8 152.8 ... 152.8 152.8 152.8]\n",
            " ...\n",
            " [107.3 107.3 107.3 ... 107.3 107.3 107.3]\n",
            " [152.8 152.8 152.8 ... 152.8 152.8 152.8]\n",
            " [152.8 152.8 152.8 ... 152.8 152.8 152.8]]\n"
          ]
        }
      ],
      "source": [
        "print(info_tensor[:,:,6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ουσιαστικά αναζητούμε τα **Χ και Υ** του RFID TAG, γνωρίζοντας το πως **κινήθηκε** και την μέτρηση της **φάσης** του."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Αποθηκεύουμε σε μεταβλητές τα μεγέθη του input και του output για τα γραμμικά μοντέλα."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6000, 3)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_len = rfid_label.shape[1]\n",
        "input_len = info_tensor.shape[1] * info_tensor.shape[2]\n",
        "\n",
        "input_len,output_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_func_eval(X_main, X_holdout, y_main, y_holdout, batch_size = 32):\n",
        "    # Compute abs max PER FEATURE on training data\n",
        "    abs_max = np.abs(X_main).max(axis=(0,1))  # max per feature over (samples, time)\n",
        "\n",
        "    # Prevent division by zero\n",
        "    abs_max[abs_max == 0] = 1.0\n",
        "\n",
        "    # Normalize per feature\n",
        "    X_train_norm = X_main / abs_max  # shape (N_train, 500, 4)\n",
        "    X_test_norm = X_holdout / abs_max    # shape (N_test, 500, 4)\n",
        "\n",
        "    # Now reshape for linear model\n",
        "    X_train_scaled = X_train_norm.reshape(len(X_train_norm), -1)  # (N_train, 2000)\n",
        "    X_test_scaled = X_test_norm.reshape(len(X_test_norm), -1)     # (N_test, 2000)\n",
        "\n",
        "    # Scale Y with StandardScaler (correct approach)\n",
        "    scaler_Y = StandardScaler()\n",
        "    y_main_scaled = scaler_Y.fit_transform(y_main)\n",
        "    y_holdout_scaled = scaler_Y.transform(y_holdout)\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_main_tensor = torch.tensor(y_main_scaled, dtype=torch.float32)\n",
        "    y_holdout_tensor = torch.tensor(y_holdout_scaled, dtype=torch.float32)\n",
        "\n",
        "    # Dataloaders\n",
        "    train_data = TensorDataset(X_train_tensor, y_main_tensor)\n",
        "    test_data = TensorDataset(X_test_tensor, y_holdout_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader, scaler_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_func_cv(input_array, labels, train_idx, val_idx, batch_size=32):\n",
        "    # Trim into subset\n",
        "    X_train_raw = input_array[train_idx]\n",
        "    X_test_raw = input_array[val_idx]\n",
        "    y_train = labels[train_idx, :]\n",
        "    y_test = labels[val_idx, :]\n",
        "\n",
        "    # Compute abs max PER FEATURE on training data\n",
        "    abs_max = np.abs(X_train_raw).max(axis=(0,1))  # max per feature over (samples, time)\n",
        "\n",
        "    # Prevent division by zero\n",
        "    abs_max[abs_max == 0] = 1.0\n",
        "\n",
        "    # Normalize per feature\n",
        "    X_train_norm = X_train_raw / abs_max  \n",
        "    X_test_norm = X_test_raw / abs_max  \n",
        "\n",
        "    # Now reshape for linear model\n",
        "    X_train_scaled = X_train_norm.reshape(len(X_train_norm), -1)  \n",
        "    X_test_scaled = X_test_norm.reshape(len(X_test_norm), -1)   \n",
        "\n",
        "    # Scale Y with StandardScaler (correct approach)\n",
        "    scaler_Y = StandardScaler()\n",
        "    y_train_scaled = scaler_Y.fit_transform(y_train)\n",
        "    y_test_scaled = scaler_Y.transform(y_test)\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
        "\n",
        "    # Dataloaders\n",
        "    train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size)\n",
        "\n",
        "    return train_loader, test_loader, scaler_Y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Η κύρια συνάρτηση, δέχεται όλες τις παραμέτρους του μοντέλου, χωρίζει το dataset σε main και holdout, το main θα χρησιμοποιηθεί για το CV ενώ το holdout για το τελικό evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Χωρίζει το main dataset σε n_splits subsets , και προπονεί και τεστάρει το μοντέλο σε αυτά τα subsets έτσι ώστε να υπάρχει μία καλύτερη εικόνα των δεδομένων."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Μετά το CV, προπονεί το μοντέλο στο main dataset και το τεστάρει στο holdout που μέχρι τώρα δεν το έχει δει καθόλου το μοντέλο, αντιπροσωπέυοντας την real world case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validation(input_array, labels, holdout_tensor,holdout_labels, n_splits, model, model_param, loss_fn, optimizer_1, optimizer_param, scheduler_param, early_stopper_param, epochs, device, verbose = True):\n",
        "    X_main, y_main, X_holdout, y_holdout = input_array, labels, holdout_tensor, holdout_labels\n",
        "\n",
        "    # Initialize KFold\n",
        "    kf = KFold(n_splits= n_splits, shuffle= True, random_state= 42)\n",
        "\n",
        "    # Initialize arrays to store losses and epochs\n",
        "    cv_losses = []\n",
        "    epoch_array = []\n",
        "\n",
        "    # Loop over the folds to perform cross-validation\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_main)):\n",
        "        \n",
        "        print(f\"Fold {fold_idx + 1}\")\n",
        "\n",
        "        train_loader, test_loader, _ = data_func_cv(X_main, y_main, train_idx, val_idx, batch_size=BATCH_SIZE)\n",
        "        # Instantiate the model\n",
        "        model_0 = model(**model_param)\n",
        "\n",
        "        loss_fn = loss_fn\n",
        "        optimizer = optimizer_1(model_0.parameters(), **optimizer_param)\n",
        "\n",
        "        # Initialize the scheduler\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, **scheduler_param)\n",
        "\n",
        "        # Initialize early stopping\n",
        "        early_stopper = EarlyStopping(**early_stopper_param)\n",
        "\n",
        "        # Load the data\n",
        "        arr1, arr2, best_loss, epoch_stop = train_test_model(epoch = epochs,model = model_0, train_loader= train_loader, test_loader= test_loader, loss_fn= loss_fn, optimizer=optimizer, scheduler= scheduler,early_stopper= early_stopper, device=device, test= True, verbose = verbose)\n",
        "        \n",
        "        if verbose == True:\n",
        "            plot_results(arr1, arr2)\n",
        "\n",
        "        cv_losses.append(best_loss)\n",
        "        epoch_array.append(epoch_stop)\n",
        "    \n",
        "    # Evaluate the final model\n",
        "    train_loader, test_loader, scaler_Y = data_func_eval(X_main, X_holdout, y_main, y_holdout, batch_size=BATCH_SIZE)\n",
        "    print(f\"Cross-Validation finished with mean error across {n_splits} subsets = {np.mean(cv_losses)}, evaluating final model...\")\n",
        "\n",
        "    # Instantiate the model\n",
        "    final_model = model(**model_param)\n",
        "\n",
        "    final_optimizer = optimizer_1(final_model.parameters(), **optimizer_param)\n",
        "\n",
        "    # Initialize the scheduler\n",
        "    scheduler = lr_scheduler.CosineAnnealingLR(final_optimizer, **scheduler_param)\n",
        "\n",
        "    # Load the data\n",
        "    arr1= train_test_model(epoch = np.max(epoch_array),model = final_model, train_loader= train_loader, test_loader= test_loader, loss_fn= loss_fn, optimizer=final_optimizer, scheduler= scheduler,early_stopper= early_stopper, device=device, test= False, verbose= verbose)\n",
        "\n",
        "    result = eval_model_3d(model= final_model, data_loader= test_loader, scaler= scaler_Y, verbose= True)\n",
        "    return result, final_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_units=256, dropout_rate=0.1):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        \n",
        "        # Shared encoder for both antennas\n",
        "        self.shared_network = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_units),\n",
        "            #nn.LayerNorm(hidden_units),\n",
        "            #nn.Dropout(dropout_rate),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            \n",
        "            nn.Linear(hidden_units, hidden_units),\n",
        "            #nn.LayerNorm(hidden_units),\n",
        "            #nn.Dropout(dropout_rate),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Linear(hidden_units, hidden_units // 2),\n",
        "            #nn.LayerNorm(hidden_units//2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "        )\n",
        "\n",
        "        # Final layers after feature fusion\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear((hidden_units // 2), hidden_units//2),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(hidden_units//2, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, antenna1, antenna2, antenna3):\n",
        "        # Encode both inputs\n",
        "        feat1 = self.shared_network(antenna1)\n",
        "        feat2 = self.shared_network(antenna2)\n",
        "        feat3 = self.shared_network(antenna3)\n",
        "\n",
        "        # Combine features with rich interactions\n",
        "        combined = torch.cat([\n",
        "            (feat1 + feat2 + feat3) / 3\n",
        "        ], dim=1)\n",
        "\n",
        "        # Final prediction\n",
        "        output = self.fc(combined)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss train: 0.330095 | Loss test: 0.290974 | lr = 0.0008949222036187454\n",
            "Epoch 10 | Loss train: 0.144911 | Loss test: 0.157685 | lr = 0.0009791375448883913\n",
            "Epoch 20 | Loss train: 0.089874 | Loss test: 0.104264 | lr = 0.0009919403071362994\n",
            "Epoch 30 | Loss train: 0.055348 | Loss test: 0.074766 | lr = 0.0009969381457959068\n",
            "Epoch 40 | Loss train: 0.043135 | Loss test: 0.063698 | lr = 0.0009981395415115996\n",
            "Epoch 50 | Loss train: 0.030371 | Loss test: 0.055085 | lr = 0.0009990773986542855\n",
            "Epoch 60 | Loss train: 0.021258 | Loss test: 0.044125 | lr = 0.0009995479169106589\n",
            "Epoch 70 | Loss train: 0.020430 | Loss test: 0.051659 | lr = 0.0009995824538047606\n",
            "Epoch 80 | Loss train: 0.017387 | Loss test: 0.044927 | lr = 0.0009996975690565143\n",
            "Epoch 90 | Loss train: 0.019744 | Loss test: 0.048194 | lr = 0.0009996100176877405\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[45], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m scheduler_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_max\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_min\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-5\u001b[39m}  \u001b[38;5;66;03m# For CosineAnnealingLR\u001b[39;00m\n\u001b[0;32m     10\u001b[0m early_stop_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_delta\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 12\u001b[0m siameseNetwork, trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfid_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43mholdout_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mholdout_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSiameseNetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopper_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mearly_stop_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[38], line 30\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(input_array, labels, holdout_tensor, holdout_labels, n_splits, model, model_param, loss_fn, optimizer_1, optimizer_param, scheduler_param, early_stopper_param, epochs, device, verbose)\u001b[0m\n\u001b[0;32m     27\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopping(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mearly_stopper_param)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m arr1, arr2, best_loss, epoch_stop \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     plot_results(arr1, arr2)\n",
            "Cell \u001b[1;32mIn[30], line 20\u001b[0m, in \u001b[0;36mtrain_test_model\u001b[1;34m(epoch, model, train_loader, test_loader, loss_fn, optimizer, scheduler, early_stopper, device, test, verbose)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(test):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m         epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m         train_loss_arr\u001b[38;5;241m.\u001b[39mappend(epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader))\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# Scheduler update\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[27], line 19\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m antenna2 \u001b[38;5;241m=\u001b[39m X_batch[:,size: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m size]\n\u001b[0;32m     18\u001b[0m antenna3 \u001b[38;5;241m=\u001b[39m X_batch[:,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39msize:]\n\u001b[1;32m---> 19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mantenna1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantenna2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantenna3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y_batch)\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[44], line 34\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, antenna1, antenna2, antenna3)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, antenna1, antenna2, antenna3):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Encode both inputs\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     feat1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mantenna1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     feat2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_network(antenna2)\n\u001b[0;32m     36\u001b[0m     feat3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_network(antenna3)\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\jimka\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#loss_fn = nn.MSELoss()\n",
        "loss_fn = nn.HuberLoss()\n",
        "optim = torch.optim.Adam\n",
        "\n",
        "num_splits = 2\n",
        "epoch = 300\n",
        "model_params = {'input_size': int(input_len/3), 'output_size': output_len}\n",
        "optimizer_params = {'lr': 1e-3, 'weight_decay': 1e-4}\n",
        "scheduler_params = {'T_max': 100, 'eta_min': 1e-5}  # For CosineAnnealingLR\n",
        "early_stop_params = {'patience': 50, 'min_delta': 1e-5, 'verbose': False, 'path': 'temp_model.pth'}\n",
        "\n",
        "siameseNetwork, trained_model = cross_validation(info_tensor, rfid_label,holdout_tensor,holdout_labels, n_splits=num_splits, model= SiameseNetwork, model_param= model_params, loss_fn= loss_fn, optimizer_1= optim, optimizer_param= optimizer_params, scheduler_param= scheduler_params, early_stopper_param= early_stop_params, epochs= epoch, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1081.9419,   58.2106,  232.5885]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model(torch.Tensor(info_tensor[0,:,:4].reshape(2000,-1).T) , torch.Tensor(info_tensor[0,:,4:8].reshape(2000,-1).T), torch.Tensor(info_tensor[0,:,8:].reshape(2000,-1).T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1081.9419,   58.2106,  232.5883]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model(torch.Tensor(info_tensor[0,:,:4].reshape(2000,-1).T) , torch.Tensor(info_tensor[0,:,8:].reshape(2000,-1).T), torch.Tensor(info_tensor[0,:,4:8].reshape(2000,-1).T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([160.54328362,  54.3956607 ,  81.5       ])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rfid_label[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Η απόκλιση ευθύνεται στο ότι η είσοδος δεν είναι scaled whatever"
      ]
    },
    {
      "attachments": {
        "image.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![image.png](attachment:image.png)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
